# -*- coding: utf-8 -*-
"""app

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11iVDCBa78NRuIqmKXpFwzQUrXM7yWAFR
"""

# streamlit_loan_predictor.py
# Streamlit dashboard tailored for your model (logistic_regression_model1.pkl)
# This app expects exactly 5 numeric independent variables:
# ['LoanAmount', 'Gender', 'ApplicantIncome', 'Dependents', 'Loan_Amount_Term']
# and predicts 'Loan_Status' using a saved statsmodels Logit results object.

import streamlit as st
import joblib
import pickle
import pandas as pd
from pathlib import Path
import statsmodels.api as sm

st.set_page_config(page_title="Loan Status Predictor (Your Model)", layout="centered")
st.title("Loan Status Predictor â€” Tailored to your model")

st.markdown(
    """
    This app is configured for your logistic model that was trained with these five numeric features:

    - **LoanAmount** (numeric)
    - **Gender** (numeric: 1 = Male, 2 = Female)
    - **ApplicantIncome** (numeric)
    - **Dependents** (numeric: 0,1,2,3)
    - **Loan_Amount_Term** (numeric, months)

    The app loads `logistic_regression_model1.pkl` from `/mnt/data` (or you can upload a model). The model expected here is the statsmodels `Logit` fitted-results object (the one produced by `result = logit_model.fit()` in your script). Prediction uses the fitted model's `predict` method and a default threshold of 0.5.
    """
)

# --- Model loading ---
MODEL_PATH = Path('logistic_regression_model1.pkl')
uploaded_model = st.sidebar.file_uploader("Upload statsmodels result (.pkl/.joblib) (optional)", type=['pkl', 'joblib'])

model = None
model_source = None

# helper to safely load
def safe_load(path_or_file):
    try:
        # joblib can load both paths and file-like objects
        return joblib.load(path_or_file)
    except Exception:
        try:
            # fallback to pickle
            if hasattr(path_or_file, 'read'):
                return pickle.load(path_or_file)
            else:
                with open(path_or_file, 'rb') as f:
                    return pickle.load(f)
        except Exception as e:
            raise e

if uploaded_model is not None:
    try:
        model = safe_load(uploaded_model)
        model_source = 'uploaded file'
    except Exception as e:
        st.sidebar.error(f"Failed to load uploaded model: {e}")

if model is None and MODEL_PATH.exists():
    try:
        model = safe_load(MODEL_PATH)
        model_source = str(MODEL_PATH)
    except Exception as e:
        st.sidebar.error(f"Failed to load model from {MODEL_PATH}: {e}")

if model is None:
    st.warning("No model loaded. Upload `logistic_regression_model1.pkl` or place it in /mnt/data and refresh.")

st.sidebar.markdown('---')
st.sidebar.write(f'Model source: {model_source or "not loaded"}')

# --- Input fields (exactly your 5 features) ---
st.header("Enter applicant details (numeric inputs)")
st.info("For Gender use 1 = Male, 2 = Female. Dependents allowed: 0,1,2,3.")

loan_amount = st.number_input('LoanAmount (numeric, e.g., 120)', value=128.0)
gender = st.number_input('Gender (1=Male, 2=Female)', min_value=1, max_value=2, value=1, step=1)
applicant_income = st.number_input('ApplicantIncome (numeric, e.g., monthly INR)', value=25000.0)
dependents = st.number_input('Dependents (0,1,2,3)', min_value=0, max_value=3, value=0, step=1)
loan_amount_term = st.number_input('Loan_Amount_Term (months, e.g., 360)', value=360.0)

# Pack into DataFrame with same order used in training
feature_order = ['LoanAmount', 'Gender', 'ApplicantIncome', 'Dependents', 'Loan_Amount_Term']
X = pd.DataFrame([[loan_amount, gender, applicant_income, dependents, loan_amount_term]], columns=feature_order)

st.markdown('---')
if st.button('Predict Loan Status'):
    if model is None:
        st.error('No model loaded. Upload the statsmodels fitted result or place logistic_regression_model1.pkl in /mnt/data.')
    else:
        try:
            # statsmodels results expect a constant if model was trained with one
            X_const = sm.add_constant(X, has_constant='add')

            # Some saved objects may be the results object (has predict) or the Logit model (needs fit).
            if hasattr(model, 'predict'):
                probs = model.predict(X_const)
            else:
                # try to access .results or .fittedvalues-like attributes
                if hasattr(model, 'results') and hasattr(model.results, 'predict'):
                    probs = model.results.predict(X_const)
                else:
                    st.error('Loaded object does not support predict. Make sure you uploaded the fitted Logit results object (result = logit_model.fit()).')
                    probs = None

            if probs is not None:
                # statsmodels predict may return ndarray/Series
                prob = float(probs[0])
                pred_label = 'Approved' if prob >= 0.5 else 'Rejected'

                st.success(f'Prediction: **{pred_label}**')
                st.info(f'Probability of approval: {prob:.3f}')

                st.write('---')
                st.subheader('Input values used (single row)')
                st.dataframe(X.astype(object))
        except Exception as e:
            st.error(f'Failed to run prediction: {e}')
            st.exception(e)

st.markdown('---')
st.caption('This app assumes the model expects numeric inputs exactly in the order shown and that the fitted statsmodels results object was saved to logistic_regression_model1.pkl. If you used a different ordering or preprocessing, export a pipeline or share the model export code.')

st.markdown('## How to re-export your model (recommended)')
st.code(
"""
# In your training notebook, after fitting the model (result = logit_model.fit()):
import joblib
joblib.dump(result, 'logistic_regression_model1.pkl')

# Or using pickle:
import pickle
with open('logistic_regression_model1.pkl','wb') as f:
    pickle.dump(result, f)
"""
)
